{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828b7520",
   "metadata": {},
   "source": [
    "convert the string values to integer values using the LabelEncoder. three class values (Iris-setosa, Iris-versicolor, Iris-virginica) are mapped to the integer values (0, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b749793",
   "metadata": {},
   "source": [
    "save the label encoder as a separate object -> same encoding scheme.\n",
    "how to load the iris dataset with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e105cccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclass classification\n",
    "import pandas\n",
    "import xgboost\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# load data\n",
    "data = pandas.read_csv('iris.csv', header=None)\n",
    "dataset = data.values\n",
    "# split data into X and y\n",
    "X = dataset[:,0:4]\n",
    "Y = dataset[:,4]\n",
    "# encode string class values as integers\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder = label_encoder.fit(Y)\n",
    "label_encoded_y = label_encoder.transform(Y)\n",
    "seed = 7\n",
    "test_size = 0.33\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, label_encoded_y, test_size=test_size, random_state=seed)\n",
    "# fit model no training data\n",
    "model = xgboost.XGBClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions for test data\n",
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
    "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
    "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
    "       scale_pos_weight=1, seed=0, silent=True, subsample=1)\n",
    "Accuracy: 92.00%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1334bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBoost model automatically models the multiclass classification problem by the multi:softprob objective, a variation on the softmax loss function to model class probabilities.  the output class is converted into a one hot type encoding automatically"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
